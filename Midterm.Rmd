---
title: "Midterm"
author: "Kerem Tuncer"
date: "11/14/2021"
output:
  word_document: default
  html_notebook: default
---

```{r}
library(ri)
```

## Section 1

### Question 1

The difference-in-differences estimator is an analysis of change scores. To be more specific, it is defined as the difference in average outcome in the treatment group before and after treatment minus the difference in average outcome in the control group before and after treatment.

Now, let's prove that it is an unbiased estimator of the ATE. Firstly, we know that if we allocate subjects randomly with equal probability to treatment and control groups, the expected value of $X_i$ - a pretreatment covariate - in the treatment group will be the saame as the expected value of $X_i$ in the control group. This can be seen in equation 4.1, in which $D_i$ refers to whether a hypothetical assignment causes a subject to receive the treatment.

$$E[X_i] = E[X_i|D_i = 1] = E[X_i|D_i = 0]$$

Then, let's look at the notation for the difference-in-differences estimation of the ATE.

$$E[\widehat{ATE}] = E[Y_i - X_i | D_i = 1] - E[Y_i - X_i | D_i = 0] $$

We can enlarge the above equation with the following expected value property.

$$E[X \pm Y] = E[X] \pm E[Y]$$

$$E[\widehat{ATE}] = E[Y_i | D_i = 1] - E[X_i | D_i = 1] - E[Y_i| D_i = 0] + E[X_i|D_i = 0] $$

Given that $E[X_i|D_i = 1] = E[X_i|D_i = 0]$, we can simplify the above.


$$E[\widehat{ATE}] = E[Y_i | D_i = 1] - E[Y_i| D_i = 0] $$

This resulting equation is the same expectation as the conventional difference-in-means estimator.

The difference-in-differences estimator can be a more precise estimator of the ATE than difference-in-means depending on the scenario. If we were to regress $Y_i(1)$ on $X_i$ and regress $Y_i(0)$ on $X_i$, the sum of the slope coefficients would have to exceed 1 in order for the rescaling approach
to produce more efficient estimates of the ATE. This is visualized in equation 4.6.

$$\frac{Cov(Y_i(0), X_i)}{Var(X_i)} + \frac{Cov(Y_i(1), X_i)}{Var(X_i)} > 1$$
In conclusion, the difference-in-differences estimator can produce substantial gains in precision when a covariate strongly predicts potential outcomes.

In principle, the difference-in-differences estimator is a less precise estimator of the ATE than regression when Y is regressed on a treatment indicator and a lagged value of Y. However, if the sample size is less than 20, then controlling for covariates can lead to bias, and using the difference-in-differences estimator is probably a safer strategy than regression adjustment if the goal is to estimate the ATE more precisely.

### Question 2

Blocking's advantage over regression-based covariate adjustment tends to be modest in samples with more than 100 observations. However, in small samples - especially when N < 20 - blocking has two advantages over covariate adjustment: blocking improves precision because it eliminates the collinearity penaty, and the difference-in-means estimator remains unbiased, whereas regression may be biased.

In addition to statistical advantages, blocking also has two conceptual advantages over covariate adjustment. Firstly, it makes transparent the researcher's prior beliefs about which covariates are most likely to predict outcomes. Additionally, by eliminating the correlation between the blocked covariates and treatment assignment, it sidesteps the problems of interpretation that arise when covariate adjusted and unadjusted estimates differ.

There are basically no disadvantages of blocking vis-a-vis covariate adjustment. Even if blocks were formed using a covariate that fails to predict experimental outcomes, the estimates remain unbiased and have no more sampling variability than the estimates one would have obtained from a complete randomization.

### Question 3

One statistical advantage of placebo design is that it screens out Never-Takers. Therefore, the compliers in the treated state can then be compared directly to Compliers in the untreated state, which eliminates the noise generated by the presence of Never-takers in both the treatment and control groups. So, by isolating the compliers, the placebo design moves us from an experiment with noncompliance to the familiar situation where there are two assigned groups and "full compliance."

However, a disadvantage arising from a placebo design is that not all the Compliers receive an actual treatment; half of those who might be treated are given a placebo, which means that the resources expended to contract them are wasted.

On pg. 162, we are told that when $ITT_D > 1/2$, then a placebo-design is not preferable to the conventional design. To put it simply, the placebo-design design provides estimates with more sampling variability when Compliers make up at least half of the sample.

## Section 2

### Question 1

```{r, eval = FALSE}
  ## Use the covariates that are significant predictors in the control group

  list_a <- NULL #assigns a list with zero length to list_a; we will populate it with the loop
  for (i in 1:length(v)){ # this is the beginning of a for loop. the code inside the parentheses will start by replacing i with 1 and use 1 for the code inside {} wherever i is used. Then, this loop will perform the same actions for all values between 1 and the length of the v list (including 1 and the length).
  pvalue <- summary(lm(Y[Z==0] ~ v[[i]][Z==0]))$coefficients[,4][2] #lm() conducts a linear regression where the dependent variable is Y and the independent variable is the ith list (variable) in list v. However, the [Z==0] means that the regression is conducted only on observations whose Z value is zero. Finally, it assigns the p-value of the independent variable's coefficient to pvalue. To achieve this, the summary() function is used which outputs a list. Then, the p-values are located in the 4th column and the 2nd row of coefficients sublist - which is inside of the summary() functions output.
  if (pvalue < 0.05) {#sets up an if statement. The code inside the {} will run only if the expression inside the parentheses - which is pvalue < 0.05 - evaluates to TRUE.
    list_a <- c(list_a, colnames(v)[i]) #combines list_a and the name of the sublist in v that produced a statistically significant p-value. Given that this is a for loop, the list_a list will be populated with the names of sublists of v that produced statistically significant p-values.
  }} #ends the for-loop
  if (is.null(list_a)) {#sets up an if statement, the code inside the {} will run only if the expression inside the parentheses - which is whether list_a is null - evaluates to TRUE.
    fit_significant <- lm(Y ~ Z) #run a linear regression with the Y as the dependent variable and Z as the independent variable.
  }else{ #the code below inside the {} will run if the expression inside the parentheses - which is whether list_a is null - evaluates to FALSE.
    fit_significant <- lm(Y ~ Z + as.matrix(v[,list_a])) #run a linear regression with the Y as the dependent variable and Z & sublists that produced statistically significant p-values as the independent varibales. The v[,list_a] subsets v so that only sublists whose name appears in list_a are included, and the as.matrix() function converts it to a matrix.
    }
  est_ate_significant <- coef(fit_significant)[2] #coef() gets the coefficients of a regression object and stores them as a vector. The [2] extracts the second element in the coef() output vector, which is the coefficient estimate of Z. Then, it is assigned to est_ate_significant.

```


### Question 2

Based on the simulation results, we have the following values.

(a) The estimated ATE including all 20 covariates was 2.99691.

(b) The estimated ATE including significant covariates was 2.985972

(c) The estimated ATE including covariates that show imbalance was 3.006372.

(d) The estimated ATE excluding covariates was 3.000053.

(e) The estimated ATE including five real covariates was 2.996253.

Given this information, all of the estimators appear to be unbiased. These estimates are about as close as we can get to the true ATE of 2.985141. with 10,000 draws. If we were to re-run the simulation with 50,000 draws, we would expect the estimated ATEs for all 5 of the methods to be even closer to the true ATE.

### Question 3

Above, we have established that all of the estimators we have tried are unbiased. For unbiased estimators, we know the following;

$$MSE_{\hat\theta} = Var(\hat\theta)$$

With this formula in mind, let's compute the MSE of the five estimators.

```{r}
true_ate <- 2.985141

output <- read.csv("output_midterm_code.csv")
dat <- as.data.frame(output)

var(output[,1])
mean((dat$est_ate_all - true_ate)^2) 

var(output[,2])
mean((dat$est_ate_significant - true_ate)^2)

var(output[,3])
mean((dat$est_ate_imbalanced - true_ate)^2)

var(output[,4])
mean((dat$est_ate_no - true_ate)^2)

var(output[,5])
mean((dat$est_ate_real - true_ate)^2)

```

As, we had expected the variance of the estimators is almost equal to the MSE and would have been even closer if we had more draws. We see that using the five real covariates produced the lowest variance and the mean square error (1.554171). Likewise, using only the statistically significant covariates (1.582769) and all the covariates (1.598621) also produced relatively low variance and mean squared error.

In contrast, the estimators using covariates showing imbalance (2.002959) and excluding covariates (2.138442) produced relatively higher variance and mean squared error.

### Question 4

Based on my answers to questions 2 and 3, I have observed that all five of the estimators were unbiased. On the other hand, the mean squared errors were pretty different. Given that researchers may not know in advance what the "real" covariates are, I would advise them to first identify the covariates that significantly predict (at p < .05) outcomes in the control group and then include these covariates for the estimation of the average treatment effect. This is because this estimator was unbiased and also produced the lowest variance of the estimates and the lowest mean squared error.

## Section 3


### Question 1

```{r}
library(AER)
vietnam <- read.csv("Exam Vietnam Data 2021.csv")
```

### Question 2

```{r}
vietnam$Served <- ifelse(vietnam$Served == 1, 0, 1)
```

### Question 3

```{r}
hist(vietnam$Afg_Mistake)
prop.table(table(vietnam$Afg_Mistake))
```

From the histogram, we can see that there were two possible outcomes: 2 standing for Yes and 1 standing for No. The bar on the left indicates that approximately 300 participants answered No to the question "was Afghanistan a make?" The bar on the right indicates that approximately 340 participants answered Yes. This means that over 50% of the participants thought that Afghanistan was a mistake.

### Question 4

Let's first begin by taking a look at the mean of the drafted variable in each draft subgroup.

```{r}
tapply(vietnam$Drafted, vietnam$Year, mean)
```

It is clear that the probability appears to be much higher in the 1952 group than in the other two groups. I suspect that there could be different probabilities of being drafted by birth year. To test this further, I will conduct an F-test.


```{r}
set.seed(1907)
Z <- vietnam$Drafted
covs <- as.matrix(as.factor(vietnam$Year))

probs <- genprobexact(Z)
numiter <- 50000
perms <- genperms(Z,maxiter=numiter)
numiter <- ncol(perms)

Fstat <- summary(lm(Z~covs))$fstatistic[1] # observed F statistic
Fstatstore <- rep(NA,numiter)
for (i in 1:numiter) {
  Fstatstore[i] <- summary(lm(perms[,i]~covs))$fstatistic[1]
}

mean(Fstatstore >= Fstat) 

```

The p-value was 0.02478, which is lower than the 0.05 threshold. Thus, we can reject the null hypothesis that the birth year predicts being drafted no better than would be expected by chance. We have enough evidence to conclude that there are different probabilities of being drafted by birth year.

### Question 5

```{r}
summary(lm(Served ~ Drafted, data = vietnam, subset = (Year == 1950)))
exp(coef(lm(Served ~ Drafted, data = vietnam, subset = (Year == 1950))))
summary(lm(Served ~ Drafted, data = vietnam, subset = (Year == 1951)))
exp(coef(lm(Served ~ Drafted, data = vietnam, subset = (Year == 1951))))
summary(lm(Served ~ Drafted, data = vietnam, subset = (Year == 1952)))
exp(coef(lm(Served ~ Drafted, data = vietnam, subset = (Year == 1952))))
```

Among those who were born in 1950, being drafted increased the odds of serving (versus not serving) to increase by a factor of 1.208366.
Among those who were born in 1951, being drafted increased the odds of serving (versus not serving) to increase by a factor of 1.21958.
Among those who were born in 1952, being drafted increased the odds of serving (versus not serving) to increase by a factor of 1.335647.

### Question 6

There are a total of four groups of subjects. For the following, let's call $z_i$ the draft status and $d_i$ serving in the military. We will begin by identifying these groups before assigning them to latent types.

The first group includes people who were not drafted and who did not serve. Therefore, their $z_i$ will be equal to 0 and their $d_i$ will be equal to 0.

The second group includes people who were not drafted but did serve. Therefore, their $z_i$ will be equal to 0 and their $d_i$ will be equal to 1.

The third group includes people who were drafted but did not serve. Therefore, their $z_i$ will be equal to 1 and their $d_i$ will be equal to 0.

The fourth group includes people who were drafted and did serve. Therefore, their $z_i$ will be equal to 1 and their $d_i$ will be equal to 1.

Now, let's move on to latent types.

Subjects in the first and the fourth groups belong to the latent type of Compliers. These, subjects served in the military ($d_i = 1$) when they were drafted ($z_i = 1$) and did not serve ($d_i = 0$) when not drafted ($z_i = 0$).

Subjects in the second group belong to the latent type of Always-Takers. This is because they served in the military ($d_i = 1$) even though they were not drafted ($z_i = 0$).

Subjects in the third group belong to the latent type of Never-Takers. This is because they did not serve in the military ($d_i = 0$) even though they were drafted ($z_i = 1$).

Subjects who would serve if and only if they were not drafted ($d_i(0) = 1$) and would not serve if and only if they were drafted ($d_i(1) = 0$) would be defiers. If we were to assume monotonicity, then none of the subjects would be in this latent type.

### Question 7

```{r}
library(descr)
born_1950 <- vietnam[vietnam$Year == 1950,]
crosstab(born_1950$Drafted, born_1950$Served, prop.t = T, plot = F)
```

The upper-bound for Compliers will be 41.1% + 19.3% = 60.4%.
The upper-bound for Always-Takers will be 19.3% + 11.4% = 30.7%.
The upper-bound for Never-Takers will be 41.1% + 28.2% = 69.3%.
The upper-bound for Defiers (assuming the violation of monotonicity) will be 11.4% + 28.2% = 39.6%.

```{r}
born_1951 <- vietnam[vietnam$Year == 1951,]
crosstab(born_1951$Drafted, born_1951$Served, prop.t = T, plot = F)
```

The upper-bound for Compliers will be 42.8% + 17.6% = 60.4%.
The upper-bound for Always-Takers will be 17.6% + 8.1% = 25.7%.
The upper-bound for Never-Takers will be 42.8% + 31.5% = 74.3%.
The upper-bound for Defiers will be 8.1% + 31.5% = 39.6%.

```{r}
born_1952 <- vietnam[vietnam$Year == 1952,]
crosstab(born_1952$Drafted, born_1952$Served, prop.t = T, plot = F)
```

The upper-bound for Compliers will be 35.2% + 24.9% = 60.1%.
The upper-bound for Always-Takers will be 24.9% + 5.2% = 30.1%.
The upper-bound for Never-Takers will be 35.2% + 34.7% = 69.9%.
The upper-bound for Defiers will be 5.2% + 34.7% = 39.9%.

### Question 8

In this context, monotonicity presupposes that being drafted will never cause someone who would otherwise serve in the military to not serve in the military. In other words, there should not be any subjects who would serve if and only if they were not drafted. Likewise, there should not be any subjects who would not serve in the military if and only if they were in drafted. If these conditions were satisfied, then the monotonicity assumption would be satisfied.

### Question 9

Excludability requires that being drafted or not influences attitudes toward US military involvement in Afghanistan only through military service. This assumption would be violated if being drafted or not affected attitudes toward US military involvement in Afghanistan for reasons other than military service.

Let's think of an example where excludability would be violated. A poor individual was drafted and thought to himself that the drafting procedure favored rich people, which is why he was drafted. Therefore, he began thinking that he cannot trust the government and would distrust any government action, including military involvement. In this scenario, the draft status may affect the trust to government, which in turn may affect  attitudes toward US military involvement in Afghanistan in ways that are not transmitted through military service. This would be indicate a violation of the excludability assumption.

### Question 10

Let's define $\textbf{z}$ as a list of treatment assignments for each of the N subjects. The treatment assignment of subject i is one of the N elements of this list. Part A of the non-interference assumption states that a given subject will keep the same treatment even when the assignments of other subjects change.

$$d_i(\textbf{z}) = d_i(\textbf{z}')\; if \;\ z =z'$$

This Part A of the non-interference assumption is what allows us to define the $ITT_{i,D}$ as the subject-level intent-to-treat effect of $z_i$ on $d_i$.

$$ITT_{i,D} = d_i(1) - d_i(0)$$

Therefore, the ITT_D will be $E[d_i(1)] - E[d_i(0)]$.

Likewise, Part B of the non-interference assumption states that the potential outcomes are affected by the subject's own assignment and the treatment that the subject receives as a consequences of that assignment. Other subjects' assignments and treatments are assumed to have no bearing on one's outcomes.

$$Y_i(z,\textbf{d}) = Y_i(z',\textbf{d'}) \; if \; z_i = z' \: and \: \textbf{d}_i = \textbf{d}_i'$$

This Part B of the non-interference assumption is what allows us to define the $ITT_{i,Y}$ as the subject-level intent-to-treat effect of $z_i$ on $Y_i$.

$$ITT_{i,Y} = Y_i(z = 1) - Y_i(z = 0)$$
Therefore, the ITT will be $E[Y_i(z = 1)] - E[Y_i(z = 0)]$.

Now, we have to apply the formulas for the ITT and the ITT_D to two-sided non-compliance.

The ITT may be expressed as a weighted average of the ITT among Never-Takers, Always-Takers, Compliers, and Defiers. I do not know how to do separate lines in inline math, so I will write them separately.

$$ ITT_{C}\pi_c = E[(Y_i(d(1)) - Y_i(d(0))) | d_i(1) - d_i(0) = 1]\pi_{C}$$
$$ ITT_{AT}\pi_{AT} = E[(Y_i(d(1)) - Y_i(d(0))) | d_i(1) = d_i(0) = 1]\pi_{AT}$$
$$ ITT_{NT}\pi_{NT} = E[(Y_i(d(1)) - Y_i(d(0))) | d_i(1) = d_i(0) = 0]\pi_{NT}$$
$$ ITT_{D}\pi_{D} = E[(Y_i(d(1)) - Y_i(d(0))) | d_i(1) - d_i(0) = -1]\pi_{D}$$

$$ITT = ITT_C\pi_{C} + ITT_{AT}\pi_{AT} + ITT_{NT}\pi_{NT} + ITT_D\pi_{D}$$

The exclusion restriction - which is $Y_i(z,d) = Y_i(d)$ - tells us that the terms for Always-Takers and Never-Takers are zero because they never change their treatment status when assignments change. Likewise, the monotonicity assumption takes out the term for the Defiers because it assumes that $\pi_D = 0$.

Therefore, the ITT reduces to the following;

$$ ITT = E[(Y_i(d(1)) - Y_i(d(0))) | d_i(1) - d_i(0) = 1]\pi_{C}$$

The same logic can be used for the ITT_D, where we can write the ITT_D of this experiment as a weighted average of the ITT_D of each of the four subgroups. The exclusion restriction will drop the ITT_D terms of Always-Takers and Never-Takers, whereas the monotonicity assumption will drop the term of the Defiers. In the end, we will be left with the following;

$ITT_D = E[(d_i(1) - d_i(0)) | d_i(1) - d_i(0) = 1]*\pi_C = \pi_C$

Lastly, we know that the CACE is equal to the following;

$$CACE = \frac{ITT}{ITT_D}$$
Given that we can identify the ITT and the ITT_D from the dataset we have, we should also be able to identify the CACE assuming monotonicity, excludability, and non-interference.

### Question 11

```{r}
lm(Served ~ Drafted, born_1950)
lm(Served ~ Drafted, born_1951)
lm(Served ~ Drafted, born_1952)
```

The estimated ITT_D of Drafted on Served for those born in 1950 is 0.1893.
The estimated ITT_D of Drafted on Served for those born in 1951 is 0.1985.
The estimated ITT_D of Drafted on Served for those born in 1952 is 0.2894.

```{r}
probs <- genprobexact(vietnam$Drafted, blockvar = vietnam$Year)
w <- vietnam$Drafted/probs + (1-vietnam$Drafted)/(1-probs) 

lm(vietnam$Served ~ vietnam$Drafted , weights = w)
```

The ITT_D for the entire subject pool is 0.2260. This means that compliers comprise 22.60% of the sample pool.

### Question 12

```{r}
lm(Afg_Mistake ~ Drafted, born_1950)
lm(Afg_Mistake ~ Drafted, born_1951)
lm(Afg_Mistake ~ Drafted, born_1952)
```

The estimated ITT of Drafted on the survey outcome for those born in 1950 is -0.009434.
The estimated ITT of Drafted on the survey outcome for those born in 1951 is 0.01949.
The estimated ITT of Drafted on the survey outcome for those born in 1952 is 0.1648.

```{r}
lm(vietnam$Afg_Mistake ~ vietnam$Drafted , weights = w)
```

The estimated ITT for the total subject pool is 0.05891. Therefore, we can say that being assigned to the treatment group (which means being drafted) increased the attitudes towards involvement in Afghanistan by 0.05891 points.

### Question 13

```{r}
set.seed(1234567)
# Generate permutation matrix
probs <- genprobexact(vietnam$Drafted, blockvar = vietnam$Year)
perms <- genperms(vietnam$Drafted,maxiter=50000)
## Too many permutations to use exact method.
## Defaulting to approximate method.
## Increase maxiter to at least Inf to perform exact estimation.
# Generate outcomes under sharp null
Ys <- genouts(vietnam$Afg_Mistake, vietnam$Drafted, ate=0)
# Generate sampling distribution under sharp null
distout <- gendist(Ys,perms,prob=probs)
ITT <- estate(vietnam$Afg_Mistake, vietnam$Drafted,prob=probs)

# Two-sided p-value
p.value.twosided <- mean(abs(distout) >= abs(ITT))
p.value.twosided

```

The number of simulated ITTs that were as large in absolute value as the actual estimated ATE is 6803, corresponding to a p-value of 0.13606, for the two-tailed test. We are using the two-tailed test because we are interested in seeing if the intent to treat caused any effect (regardless of the direction of the effect). Our sharp null hypothesis was that that ITT is equal to 0 for all i. The alternative hypothesis is that ITT is not equal to 0 for all i. Given that, our p-value is much higher than 0.05, we do not have enough evidence to reject the null hypothesis. We conclude that the estimated ITT is zero for all of our observations.


### Question 14

```{r}
ITT_D_1950 <- lm(Served ~ Drafted, born_1950)$coefficients[2]
ITT_D_1951 <- lm(Served ~ Drafted, born_1951)$coefficients[2]
ITT_D_1952 <- lm(Served ~ Drafted, born_1952)$coefficients[2]

ITT_1950 <- lm(Afg_Mistake ~ Drafted, born_1950)$coefficients[2]
ITT_1951 <- lm(Afg_Mistake ~ Drafted, born_1951)$coefficients[2]
ITT_1952 <- lm(Afg_Mistake ~ Drafted, born_1952)$coefficients[2]

CACE_1950 <- ITT_1950 / ITT_D_1950
CACE_1951 <- ITT_1951 / ITT_D_1951
CACE_1952 <- ITT_1952 / ITT_D_1952

unname(CACE_1950)
unname(CACE_1951)
unname(CACE_1952)
```

The estimated CACE for those born in 1950 is -0.04984424.
The estimated CACE for those born in 1951 is 0.09815951.
The estimated CACE for those born in 1952 is 0.5694401.

```{r}
unname(lm(vietnam$Afg_Mistake ~ vietnam$Drafted , weights = w)$coefficients[2] / lm(vietnam$Served ~ vietnam$Drafted , weights = w)$coefficients[2])
```
The estimated CACE for the entire subject pool is 0.2606774. The estimated average treatment effect of military service among Compliers is a 0.2606774 point increase in the attitudes towards involvement in Afghanistan.

### Question 15

What the researchers is doing can be modeled with the following equation;

$$Y_i = a + bd_i + cX_i + (u_i-cX_i)$$
In the above, the intercept a is equal to the average value of the untreated potential outcomes for all N subjects and the term cX represents the birth year covariate. But most importantly, the slope b represents the shift in average potental outcomes, so the ATE.

Given that this study had two-sided non-compliance and assumes monotonicity, the slope b is trying to estimate a weighted average of the ATE among the compliers, never-takers, and the always takers. Hence. the slope b represents the following;

$$E[Y_i(d = 1) - Y_i(d = 0)|C]*\pi_{C} + E[Y_i(d = 1) - Y_i(d = 0)|NT]*\pi_{NT} + E[Y_i(d = 1) - Y_i(d = 0)|AT]*\pi_{AT} $$
The bias of regressing the survey outcome measure on Served (controlling for year) comes from the fact that the experiment provides no information about the average treatment effect among Never-Takers and Always-Takers. Hence, the second term and the third term on the above equation cannot be properly estimated. To be more specific, we do not observe $E[Y_i(d = 1)]$ among Never-takers and $E[Y_i(d = 0)]$ among Always-takers. In conclusion, the bias comes from the fact that the researcher's regression estimates values that cannot be estimated by a study that has two-sided non-compliance.


## Section 4

```{r}
varp <- function(x) mean((x-mean(x))^2)

N <- 4
m <- 2

control <- c(1,2,4,5)
treat <- c(5,4,3,2)

var.c <- varp(control)
var.t <- varp(treat)

cov <- (N-1)/N*cov(control, treat)

se <- sqrt((1/(N-1))*(((m*var.c)/(N-m)) + ((var.t*(N-m))/(m)) + (2*cov)))
se

var.c
var.t
cov
```

Subject pool 1 produces a standard error of 0.2886751.

```{r}
control <- c(1,2,4,5)
treat <- c(2,3,4,5)

var.c <- varp(control)
var.t <- varp(treat)

cov <- (N-1)/N*cov(control, treat)

se <- sqrt((1/(N-1))*(((m*var.c)/(N-m)) + ((var.t*(N-m))/(m)) + (2*cov)))
se

var.c
var.t
cov
```

Subject pool 2 produces a standard error of 1.554563.

```{r}
control <- c(3,3,3,3)
treat <- c(5,4,3,2)

var.c <- varp(control)
var.t <- varp(treat)

cov <- (N-1)/N*cov(control, treat)

se <- sqrt((1/(N-1))*(((m*var.c)/(N-m)) + ((var.t*(N-m))/(m)) + (2*cov)))
se

var.c
var.t
cov
```

Subject pool 3 produces a standard error of 0.6454972.

The subject pool 1 has a negative covariance between the untreated potential outcomes and the treated potential outcomes. Therefore, it makes sense that it produced the smallest standard error, meaning that it will yield results with the smallest sampling variability.

The subject pool 2 has the highest covariance term and also has a high variance in the control group. Therefore, it makes sense that it produced the largest standard error, meaning that it will yield results with the most sampling variability.

There are several implications of this exercise for how researchers should go about selecting subjects and devising experimental interventions. Firstly, we saw that having negative covariance between the potential untreated and treated outcomes played a big role in decreasing sampling variability. Therefore, researchers should devise experimental treatments - if they can - that would help those with lower potential untreated outcomes the most. Secondly, we saw that having low variance in the treatment and the control group also played a role in decreasing sampling variability. Therefore, reseachers should conduct experiments on observations that are as similar as possible in terms of their potential outcomes, which can be achieved by measuring outcomes as accurately, blocking, or using change scores.




